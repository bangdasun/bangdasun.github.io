<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Machine Learning Overview Series (4) - Classification Tree | Bangda Sun | Practice makes perfect</title>

  
  <meta name="author" content="Bangda">
  

  
  <meta name="description" content="Play with data">
  

  
  
  <meta name="keywords" content="Decision Tree,Classification">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="Machine Learning Overview Series (4) - Classification Tree"/>

  <meta property="og:site_name" content="Bangda Sun"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Bangda Sun" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX","output/HTML-CSS"],
    extensions: ["tex2jax.js","Safe.js"]
  });
  </script>
<script type="text/javascript" async="async"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML,Safe">
</script>
</script>
</head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">Bangda Sun</a>
    </h1>
    <p class="site-description">Practice makes perfect</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
        <li><a href="/tags">Tags</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>Machine Learning Overview Series (4) - Classification Tree</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2017/09/16/ml-overview-classification-tree/" rel="bookmark">
        <time class="entry-date published" datetime="2017-09-16T17:35:00.000Z">
          2017-09-16
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>Decision tree for classification problems</p>
<a id="more"></a>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>Last time we go through regression tree: using decision tree to tackle regression problem. It’s pretty reasonable that we can also apply decision tree on classification problem. To make this blog easier to read, I use binary classification tree which means we use decision tree to solve binary classification problem.</p>
<h3 id="2-Mathematical-Basis"><a href="#2-Mathematical-Basis" class="headerlink" title="2. Mathematical Basis"></a>2. Mathematical Basis</h3><h4 id="2-1-Comparisons-with-Regression-Tree"><a href="#2-1-Comparisons-with-Regression-Tree" class="headerlink" title="2.1 Comparisons with Regression Tree"></a>2.1 Comparisons with Regression Tree</h4><p>To convert regression problem to classification problem, there are several points we need to clarify:</p>
<ol>
<li>How to predict the class label of a region? In regression, we use \(\bar{y}\);</li>
<li>How to measure the performance of one split? In regression, we use squared loss function;</li>
</ol>
<p>For a certain region (which may include both two classes), we define the class label of the region to be the <strong>mode</strong> of labels of data points in the region, a.k.a <strong>“Majority Vote”</strong>. Then we can calculate error. Based on our definition of region label assignment, the error is the proportion of data points in that region that don’t belong to the class that region label indicates, the error produced by one split is</p>
<p>\[<br>L = \sum^{2}_{r=1}p_{r}\sum_{x_{i}\in R_{r}}\mathbb{I}\{y_{i}\neq \hat{y}_{r}\}<br>\]</p>
<p>where \(\hat{y}_{r}\) is the mode of observation labels in region \(r\), \(p_{r}\) is the proportion of observation in the region to the total sample size. This is also know as <strong>0-1 loss</strong>.</p>
<h4 id="2-2-Measures-of-Node-Impurity"><a href="#2-2-Measures-of-Node-Impurity" class="headerlink" title="2.2 Measures of Node Impurity"></a>2.2 Measures of Node Impurity</h4><p>However this measure for error is not sensitive for tree growing (mentioned in page 315, Introduction to statistical learning), therefore two other loss functions are more widely used in practice.</p>
<ol>
<li><strong>Gini index</strong>:</li>
</ol>
<p>\[<br>L = \sum^{2}_{r=1}p_{r}\sum^{1}_{k=0}p_{rk}(1-p_{rk}).<br>\]</p>
<ol>
<li><strong>Cross entropy</strong></li>
</ol>
<p>\[<br>L = -\sum^{2}_{r=1}p_{r}\sum^{1}_{k=0}p_{rk}\log(p_{rk}).<br>\]</p>
<p>where \(p_{rk}\) is the proportion of class \(k\) in region \(r\).</p>
<p>We can plot them together (assume there are two regions and they are equal sized).</p>
<p><img src="/images/loss-classification-tree.png" style="width: 650px; height: 400px"> </p>
<p>When the region is mostly one category, Gini index and cross entropy will take a <strong>smaller</strong> value (which means node impurity is higher, as shown in the plot), they are better measures of the node purity.</p>
<h3 id="3-Implementation"><a href="#3-Implementation" class="headerlink" title="3. Implementation"></a>3. Implementation</h3><p>Since we already implemented regression tree before, we just need to update the loss function and prediction function. Here is the <a href="https://github.com/bangdasun/Algorithms/blob/master/machine-learning/classification/classification-decision-tree/CART-C.py" target="_blank" rel="external">source code</a> and <a href="https://github.com/bangdasun/Algorithms/blob/master/machine-learning/classification/classification-decision-tree/CART-C.ipynb" target="_blank" rel="external">demo</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">In [9]: tree = ClassificationTree()</div><div class="line">        tree.build_tree(X, y, 2, 3)</div><div class="line">        tree.print_tree(tree.root)</div><div class="line">Out[9]: [X0 &lt; 6.642287351]</div><div class="line">        -[X0 &lt; 2.771244718]</div><div class="line">        --[[ 0.]]</div><div class="line">        --[X0 &lt; 3.678319846]</div><div class="line">        ---[[ 0.]]</div><div class="line">        ---[[ 0.]]</div><div class="line">        -[X0 &lt; 7.497545867]</div><div class="line">        --[[ 1.]]</div><div class="line">        --[[ 1.]]</div></pre></td></tr></table></figure>
<h3 id="4-References"><a href="#4-References" class="headerlink" title="4. References"></a>4. References</h3><ul>
<li>Gareth James, Daniela Witten, Trevor Hastie, Robert Tishirani, Introduction to Statistical Learning.</li>
</ul>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/Machine-Learning/">Machine Learning</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/Decision-Tree/">Decision Tree</a><a href="/tags/Classification/">Classification</a>
    </span>
    

    </div>

    
  </div>
</article>

  
<section id="comment">
  
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
  
</section>



    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    </br>
    
    &copy; 2019 Bangda
    
	
	
	
  </p>
  
  <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  
  <span id="busuanzi_container_site_pv">
    Total viewer <span id="busuanzi_value_site_pv"></span>; 
  </span>
  
  <span id="busuanzi_container_site_uv">
    Total visitor <span id="busuanzi_value_site_uv"></span>
  </span>
	
	
  <div id="disqus_thread"></div>
  <script>

  /**
   *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
   *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
   */
   
  var disqus_config = function () {
	this.page.url = 'https://bangdasun.github.io{{ page.url }}';  // Replace PAGE_URL with your page's canonical URL variable
	this.page.identifier = '{{ page.id }}'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
  };
  
  (function() { // DON'T EDIT BELOW THIS LINE
  var d = document, s = d.createElement('script');
  s.src = 'https://bangdasun-github-io.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  
  <script id="dsq-count-scr" src="//bangdasun-github-io.disqus.com/count.js" async></script>
</footer>


    
  </div>
</div>
</body>
</html>